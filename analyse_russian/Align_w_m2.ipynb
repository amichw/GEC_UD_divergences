{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_corrections(alignment_dict):\n",
    "    return len(alignment_dict) == 1 and len(alignment_dict['X']) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_tokens(m2_block):\n",
    "    unc_sentence, *edits = m2_block.splitlines()\n",
    "    unc_tokens = re.split(\n",
    "        r'\\s+',\n",
    "        unc_sentence\n",
    "    )[1:]\n",
    "    alignment_dict = {}\n",
    "    alignment_dict['X'] = [] # For additions\n",
    "\n",
    "    spans_outputs = []\n",
    "    for edit in edits:\n",
    "        coords, _, out, *_ = edit.split('|||')\n",
    "        i, j = list(\n",
    "            map(\n",
    "                int,\n",
    "                coords.split()[1:]))\n",
    "        spans_outputs.append((\n",
    "            (i,j),\n",
    "            out))\n",
    "    \n",
    "    spans_outputs.sort()\n",
    "    spans   = [el[0] for el in spans_outputs]\n",
    "    outputs = [el[1] for el in spans_outputs]\n",
    "    \n",
    "    # If the edit is one-to-one, we align the beginning\n",
    "    # of the edit with output_token_num.\n",
    "    # We also keep track of one-word additions (zero-length input\n",
    "    # spans) and deletions (zero-length output sequences).\n",
    "    # Otherwise we skip the span and increase output_token_num\n",
    "    # by the length of the output sequence.\n",
    "    last_span_end = 0\n",
    "    output_token_num = 0\n",
    "    for idx in range(len(spans)):\n",
    "        i, j = spans[idx]\n",
    "        if i > last_span_end:\n",
    "            output_token_num += i-last_span_end # Move cursor by the number of\n",
    "                                                # copied tokens.\n",
    "        out = outputs[idx]\n",
    "#         print(spans[idx], f\"inp: {' '.join(unc_tokens[i:j])}\", f\"out: {out}\")\n",
    "        out_len = len(out.split())\n",
    "        if i-j == 0: # Addition\n",
    "            if out_len == 1:\n",
    "                alignment_dict['X'].append({\n",
    "                    'idx': output_token_num,\n",
    "                    'inp': ' '.join(unc_tokens[i:j]),\n",
    "                    'out': out # For testing\n",
    "                })\n",
    "            output_token_num += out_len\n",
    "        elif out == '': # Deletion\n",
    "            if j-i == 1:\n",
    "                alignment_dict[i] = 'X'\n",
    "        elif j-i == out_len == 1: # One-to-one replacement\n",
    "            alignment_dict[i] = {\n",
    "                'idx': output_token_num,\n",
    "                'inp': ' '.join(unc_tokens[i:j]),\n",
    "                'out': out\n",
    "            }\n",
    "            output_token_num += 1\n",
    "        else: # Something else\n",
    "            output_token_num += out_len\n",
    "        last_span_end = j\n",
    "    return alignment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentences(unc_tokens, cor_tokens):\n",
    "    for i, tok in enumerate(unc_tokens):\n",
    "        print(f'{tok}[{i}]', end=' ')\n",
    "    print()\n",
    "    for i, tok in enumerate(cor_tokens):\n",
    "        print(f'{tok}[{i}]', end=' ')\n",
    "    print('\\n')\n",
    "    \n",
    "def test_alignment(m2_block, cor):\n",
    "    cor_tokens = re.split(\n",
    "        r'\\s+',\n",
    "        cor\n",
    "    )\n",
    "    cor = ' '.join(cor_tokens)\n",
    "    unc_tokens = re.split(\n",
    "        r'\\s+',\n",
    "        m2_block.splitlines()[0]\n",
    "    )[1:]\n",
    "    unc = ' '.join(unc_tokens)\n",
    "    alignment_dict = align_tokens(m2_block)\n",
    "    \n",
    "    for k, v in alignment_dict.items():\n",
    "        if v == 'X': # Don't test deletions for now\n",
    "            continue\n",
    "        if k == 'X':\n",
    "            for el in v:\n",
    "                i = el['idx']\n",
    "                out = el['out']\n",
    "                if cor_tokens[i] != out:\n",
    "                    raise ValueError(f'{k}->{i}')\n",
    "        else:\n",
    "            i = v['idx']\n",
    "            out = v['out']\n",
    "            if cor_tokens[i] != out:\n",
    "                raise ValueError(f'{k}->{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for corrected sentences where the output as per alignment\n",
    "# is not the same as per the edit annotation.\n",
    "corrected = 0\n",
    "errors = 0\n",
    "for part in [\n",
    "    'dev',\n",
    "    'train',\n",
    "    'test'\n",
    "]:\n",
    "    with open(f'm2_files/RULEC-GEC.{part}.M2', 'r') as inp:\n",
    "        m2_dev_blocks = inp.read().strip().split('\\n\\n')\n",
    "    with open(f'preprocessing/RULEC-GEC.{part}.corrected', 'r') as inp:\n",
    "        m2_dev_cor_blocks = inp.readlines()\n",
    "    assert(len(m2_dev_blocks) == len(m2_dev_cor_blocks))\n",
    "    corrected = 0\n",
    "    errors = 0\n",
    "    for i in range(len(m2_dev_blocks)):\n",
    "        alignment_dict = align_tokens(m2_dev_blocks[i])\n",
    "        if no_corrections(alignment_dict):\n",
    "            continue\n",
    "        try:\n",
    "            test_alignment(\n",
    "                m2_dev_blocks[i],\n",
    "                m2_dev_cor_blocks[i]\n",
    "            )\n",
    "            corrected += 1\n",
    "        except ValueError:\n",
    "            errors += 1\n",
    "        except IndexError:\n",
    "            errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2247"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
